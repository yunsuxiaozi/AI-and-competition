{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "128d14db",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.004968,
     "end_time": "2025-03-09T13:35:36.514296",
     "exception": false,
     "start_time": "2025-03-09T13:35:36.509328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Created by <a href=\"https://github.com/yunsuxiaozi\">yunsuxiaozi</a> 2025/03/09\n",
    "\n",
    "## Competition:<a href=\"https://www.kaggle.com/competitions/rohlik-sales-forecasting-challenge-v2/overview\">Rohlik Sales Forecasting Challenge</a>\n",
    "\n",
    "## 原始代码 <a href=\"https://www.kaggle.com/code/hardyxu52/simplified-3rd-place-solution-rohlik-sales/notebook?scriptVersionId=222614435\">Simplified 3rd Place Solution - Rohlik Sales</a>\n",
    "\n",
    "## 这里默认学习这个top方案的人都是有一定基础渴望提高的人,所以这里不会讲特别基础的东西。读者可以自行补充基础知识。\n",
    "\n",
    "#### 更多数据挖掘比赛的top方案可以关注<a href=\"https://github.com/yunsuxiaozi/AI-and-competition\">这里</a>。\n",
    "\n",
    "## 方案亮点分析(我学到了什么?)\n",
    "\n",
    "1.使用2022年1月1日以后的数据来训练模型。\n",
    "\n",
    "2.Z-score处理(x-mean)/std\n",
    "\n",
    "3.指数加权移动平均\n",
    "\n",
    "4.模型训练前后的开方和平方处理。\n",
    "\n",
    "5.其他一些离散的特征工程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b68fe",
   "metadata": {
    "papermill": {
     "duration": 0.004001,
     "end_time": "2025-03-09T13:35:36.522892",
     "exception": false,
     "start_time": "2025-03-09T13:35:36.518891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "导入一些常用的库."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da43dce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T13:35:36.532656Z",
     "iopub.status.busy": "2025-03-09T13:35:36.532330Z",
     "iopub.status.idle": "2025-03-09T13:35:39.712906Z",
     "shell.execute_reply": "2025-03-09T13:35:39.711776Z"
    },
    "papermill": {
     "duration": 3.187726,
     "end_time": "2025-03-09T13:35:39.714885",
     "exception": false,
     "start_time": "2025-03-09T13:35:36.527159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd#读取csv文件\n",
    "import numpy as np#进行矩阵运算的库\n",
    "from copy import deepcopy#浅拷贝,改copy数据,原始数据也会改,深拷贝,改copy数据原始数据不会改.\n",
    "from sklearn.model_selection import KFold#k折交叉验证.\n",
    "from xgboost import XGBRegressor, DMatrix#导入xgboost模型\n",
    "import warnings#avoid some negligible errors\n",
    "#The filterwarnings () method is used to set warning filters, which can control the output method and level of warning information.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random#provide some function to generate random_seed.\n",
    "#set random seed,to make sure model can be recurrented.\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)#numpy's random seed\n",
    "    random.seed(seed)#python built-in random seed\n",
    "seed_everything(seed=2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee5891",
   "metadata": {
    "papermill": {
     "duration": 0.004421,
     "end_time": "2025-03-09T13:35:39.723955",
     "exception": false,
     "start_time": "2025-03-09T13:35:39.719534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "导入库存的表格。\n",
    "\n",
    "观察表格可以发现,product_unique_id和name是一一对应的,unique_id和(warehouse和product_unique_id的组合)是一一对应的,所以这里在读取的时候drop warehouse和product_unique_id,因为这些已经可以用unique_id表示了.\n",
    "\n",
    "## 这里需要澄清的是有2种产品。一种是细分的产品,如:'Pastry_196',在一种产品的基础上还要具体到某种种类。一种是粗略的产品,就是后面的'common_name',也就是取name的前半部分."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c785d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T13:35:39.734905Z",
     "iopub.status.busy": "2025-03-09T13:35:39.734320Z",
     "iopub.status.idle": "2025-03-09T13:35:39.799372Z",
     "shell.execute_reply": "2025-03-09T13:35:39.798278Z"
    },
    "papermill": {
     "duration": 0.072863,
     "end_time": "2025-03-09T13:35:39.801349",
     "exception": false,
     "start_time": "2025-03-09T13:35:39.728486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>name</th>\n",
       "      <th>L1_category_name_en</th>\n",
       "      <th>L2_category_name_en</th>\n",
       "      <th>L3_category_name_en</th>\n",
       "      <th>L4_category_name_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5255</td>\n",
       "      <td>Pastry_196</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>Bakery_L2_14</td>\n",
       "      <td>Bakery_L3_26</td>\n",
       "      <td>Bakery_L4_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4948</td>\n",
       "      <td>Herb_19</td>\n",
       "      <td>Fruit and vegetable</td>\n",
       "      <td>Fruit and vegetable_L2_30</td>\n",
       "      <td>Fruit and vegetable_L3_86</td>\n",
       "      <td>Fruit and vegetable_L4_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2146</td>\n",
       "      <td>Beet_2</td>\n",
       "      <td>Fruit and vegetable</td>\n",
       "      <td>Fruit and vegetable_L2_3</td>\n",
       "      <td>Fruit and vegetable_L3_65</td>\n",
       "      <td>Fruit and vegetable_L4_34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>501</td>\n",
       "      <td>Chicken_13</td>\n",
       "      <td>Meat and fish</td>\n",
       "      <td>Meat and fish_L2_13</td>\n",
       "      <td>Meat and fish_L3_27</td>\n",
       "      <td>Meat and fish_L4_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4461</td>\n",
       "      <td>Chicory_1</td>\n",
       "      <td>Fruit and vegetable</td>\n",
       "      <td>Fruit and vegetable_L2_17</td>\n",
       "      <td>Fruit and vegetable_L3_33</td>\n",
       "      <td>Fruit and vegetable_L4_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id        name  L1_category_name_en        L2_category_name_en  \\\n",
       "0       5255  Pastry_196               Bakery               Bakery_L2_14   \n",
       "1       4948     Herb_19  Fruit and vegetable  Fruit and vegetable_L2_30   \n",
       "2       2146      Beet_2  Fruit and vegetable   Fruit and vegetable_L2_3   \n",
       "3        501  Chicken_13        Meat and fish        Meat and fish_L2_13   \n",
       "4       4461   Chicory_1  Fruit and vegetable  Fruit and vegetable_L2_17   \n",
       "\n",
       "         L3_category_name_en        L4_category_name_en  \n",
       "0               Bakery_L3_26                Bakery_L4_1  \n",
       "1  Fruit and vegetable_L3_86   Fruit and vegetable_L4_1  \n",
       "2  Fruit and vegetable_L3_65  Fruit and vegetable_L4_34  \n",
       "3        Meat and fish_L3_27         Meat and fish_L4_5  \n",
       "4  Fruit and vegetable_L3_33   Fruit and vegetable_L4_1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/inventory.csv').drop(['warehouse','product_unique_id'],axis=1)\n",
    "inventory.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeadda4f",
   "metadata": {
    "papermill": {
     "duration": 0.004386,
     "end_time": "2025-03-09T13:35:39.810795",
     "exception": false,
     "start_time": "2025-03-09T13:35:39.806409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "这里是针对日历或者说节日构造的特征。\n",
    "\n",
    "作者最后只保留了holiday,day_before_holiday和day_after_holiday这3个二元分类(bool)变量,也就是这个日期是节日当天、前一天和后一天的特征。\n",
    "\n",
    "['last_holiday_date','next_holiday_date']是字符串所以删掉。\n",
    "\n",
    "['days_since_last_holiday','days_to_next_holiday'],我觉得有用,但可能作者做过实验,发现效果不好,所以删了?\n",
    "\n",
    "['shops_closed','winter_school_holidays','school_holidays','holiday_name']比赛方提供的特征,可能没用?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b14a8ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T13:35:39.821258Z",
     "iopub.status.busy": "2025-03-09T13:35:39.820910Z",
     "iopub.status.idle": "2025-03-09T13:35:39.917813Z",
     "shell.execute_reply": "2025-03-09T13:35:39.916783Z"
    },
    "papermill": {
     "duration": 0.104058,
     "end_time": "2025-03-09T13:35:39.919441",
     "exception": false,
     "start_time": "2025-03-09T13:35:39.815383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>holiday</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>day_before_holiday</th>\n",
       "      <th>day_after_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-16</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-10</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>0</td>\n",
       "      <td>Prague_2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  holiday    warehouse  day_before_holiday  day_after_holiday\n",
       "0 2022-03-16        0  Frankfurt_1               False              False\n",
       "1 2020-03-22        0  Frankfurt_1               False              False\n",
       "2 2018-02-07        0  Frankfurt_1               False              False\n",
       "3 2018-08-10        0  Frankfurt_1               False              False\n",
       "4 2017-10-26        0     Prague_2               False              False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/calendar.csv', parse_dates=['date'])\n",
    "calendar.loc[calendar['holiday_name'].isna(), 'holiday'] = 0 \n",
    "calendar['last_holiday_date'] = calendar['date']\n",
    "calendar['next_holiday_date'] = calendar['date']\n",
    "calendar.loc[calendar['holiday'] == 0, ['last_holiday_date','next_holiday_date']] = np.nan\n",
    "calendar['last_holiday_date'] = calendar.sort_values('date').groupby('warehouse')['last_holiday_date'].ffill()\n",
    "calendar['next_holiday_date'] = calendar.sort_values('date').groupby('warehouse')['next_holiday_date'].bfill()\n",
    "calendar['days_since_last_holiday'] = ((calendar['date'] - calendar['last_holiday_date']).dt.days)\n",
    "calendar['days_to_next_holiday'] = ((calendar['next_holiday_date'] - calendar['date']).dt.days)\n",
    "calendar['day_before_holiday'] = calendar['days_to_next_holiday'] == 1\n",
    "calendar['day_after_holiday'] = calendar['days_since_last_holiday'] == 1\n",
    "calendar.drop(['last_holiday_date','next_holiday_date'],axis=1,inplace=True)\n",
    "calendar.drop(['days_since_last_holiday','days_to_next_holiday'],axis=1,inplace=True)\n",
    "calendar.drop(['shops_closed','winter_school_holidays','school_holidays','holiday_name'],axis=1,inplace=True)\n",
    "calendar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d50c381",
   "metadata": {
    "papermill": {
     "duration": 0.004672,
     "end_time": "2025-03-09T13:35:39.929019",
     "exception": false,
     "start_time": "2025-03-09T13:35:39.924347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "这里构造的是常见的时间特征,没什么好说的."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "482ef7a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T13:35:39.939856Z",
     "iopub.status.busy": "2025-03-09T13:35:39.939483Z",
     "iopub.status.idle": "2025-03-09T13:35:39.944909Z",
     "shell.execute_reply": "2025-03-09T13:35:39.943831Z"
    },
    "papermill": {
     "duration": 0.012772,
     "end_time": "2025-03-09T13:35:39.946668",
     "exception": false,
     "start_time": "2025-03-09T13:35:39.933896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_date(df):\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['days_since_2020'] = (df['date'] - pd.to_datetime('2020-01-01')).dt.days.astype('int')\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['cos_day'] = np.cos(df['day_of_year']*2*np.pi/365)\n",
    "    df['sin_day'] = np.sin(df['day_of_year']*2*np.pi/365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c42106",
   "metadata": {
    "papermill": {
     "duration": 0.004971,
     "end_time": "2025-03-09T13:35:39.957058",
     "exception": false,
     "start_time": "2025-03-09T13:35:39.952087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "折扣一般不可能是负数,所以clip是在去除异常值,统计最大折扣的时候没有type_6,这个我没有问过原作者。\n",
    "\n",
    "sell_price_main是长尾分布,所以取log。common_name是粗略的产品。\n",
    "\n",
    "然后是一些离散的特征:\n",
    "\n",
    "每天每个仓库每种粗略的产品中有几种细分的产品(比如土豆有土豆1号,土豆2号,土豆3号3种)\n",
    "\n",
    "每天每个仓库每种粗略的产品中细分产品的最大折扣的均值\n",
    "\n",
    "每天每个细分的产品在几家商店有。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad1c3a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T13:35:39.968181Z",
     "iopub.status.busy": "2025-03-09T13:35:39.967754Z",
     "iopub.status.idle": "2025-03-09T13:35:39.974399Z",
     "shell.execute_reply": "2025-03-09T13:35:39.973259Z"
    },
    "papermill": {
     "duration": 0.014284,
     "end_time": "2025-03-09T13:35:39.976286",
     "exception": false,
     "start_time": "2025-03-09T13:35:39.962002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_other(df):\n",
    "    discount_cols = ['type_0_discount','type_1_discount','type_2_discount','type_3_discount','type_4_discount','type_5_discount','type_6_discount']\n",
    "    df[discount_cols] = df[discount_cols].clip(0)\n",
    "    df['max_discount'] = df[['type_0_discount','type_1_discount','type_2_discount',\n",
    "                             'type_3_discount','type_4_discount','type_5_discount']].max(axis=1)\n",
    "    \n",
    "    df['sell_price_main'] = np.log(df['sell_price_main']) \n",
    "\n",
    "    df['common_name'] = df['name'].apply(lambda x: x[:x.find('_')])\n",
    "    df['CN_total_products'] = df.groupby(['date','warehouse','common_name'])['unique_id'].transform('nunique')\n",
    "    df['CN_discount_avg'] = df.groupby(['date','warehouse','common_name'])['max_discount'].transform('mean')\n",
    "    df['name_num_warehouses'] = df.groupby(['date','name'])['unique_id'].transform('nunique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4714826f",
   "metadata": {
    "papermill": {
     "duration": 0.005014,
     "end_time": "2025-03-09T13:35:39.987036",
     "exception": false,
     "start_time": "2025-03-09T13:35:39.982022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "这里对sell_price_main和total_orders这2个特征做了重点的特征工程,可能是作者观察到这2个特征特别重要吧.具体做了什么,可以看注释。\n",
    "\n",
    "普通的窗口平均就是设置一个窗口,然后对这个窗口内的数求平均值。指数加权移动平均则是\n",
    "\n",
    "$EWMA_{t}=αx_{t}+(1−α)⋅EWMA_{t−1}$\n",
    "\n",
    "比如一组数据是[1,2,3],α=0.1,则 $EWMA_{0}=1$\n",
    "\n",
    "$EWMA_{1}=0.1*2+0.9*1=1.1$   $EWMA_{2}=0.1*3+0.9*1.1=1.29$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d470fe2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T13:35:39.998391Z",
     "iopub.status.busy": "2025-03-09T13:35:39.998041Z",
     "iopub.status.idle": "2025-03-09T13:35:40.006178Z",
     "shell.execute_reply": "2025-03-09T13:35:40.005161Z"
    },
    "papermill": {
     "duration": 0.015548,
     "end_time": "2025-03-09T13:35:40.007624",
     "exception": false,
     "start_time": "2025-03-09T13:35:39.992076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_combined(df):\n",
    "    #这里没仔细看代码,根据作者的命名,应该是过去28天这个商店营业了几天\n",
    "    df['num_sales_days_28D'] = pd.MultiIndex.from_frame(df[['unique_id','date']]).map(df.sort_values('date').groupby('unique_id').rolling(\n",
    "        window='28D', on='date', closed='left')['date'].count().fillna(0))\n",
    "\n",
    "    print(\"< sell_price_main features >\")\n",
    "    #这里首先对sell_price_main特征得到了标准化以后的数值(x-mean)/std\n",
    "    #然后减去每天每个仓库的 price-scaled的均值,看的是这个sell_price_main在当天这个仓库的相对的位置.\n",
    "    mean_prices = df.groupby(df['unique_id'])['sell_price_main'].mean()\n",
    "    std_prices = df.groupby(df['unique_id'])['sell_price_main'].std()\n",
    "    df['price_scaled'] = np.where(df['unique_id'].map(std_prices) == 0, 0, \n",
    "                                  (df['sell_price_main'] - df['unique_id'].map(mean_prices))/df['unique_id'].map(std_prices))\n",
    "    #days_since_2020其实和date代表的意思是相同的,只是表现的形式不同.\n",
    "    df['price_detrended'] = df['price_scaled'] - df.groupby(['days_since_2020','warehouse'])['price_scaled'].transform('mean')\n",
    "    df.drop('price_scaled',axis=1,inplace=True)\n",
    "\n",
    "    print(\"< total orders features >\")\n",
    "    #每天每个商店total_orders的中位数\n",
    "    warehouse_stats = df.groupby(['date','warehouse'])['total_orders'].median().rename('med_total_orders').reset_index().sort_values('date')\n",
    "    #对每个商店的total_orders的中位数进行了指数移动平均\n",
    "    warehouse_stats['ewmean_orders_56'] = warehouse_stats.groupby('warehouse')['med_total_orders'].transform(lambda x:x.ewm(alpha=1/56).mean())\n",
    "    df['ewmean_orders_56'] = pd.MultiIndex.from_frame(df[['warehouse','date']]).map(\n",
    "        warehouse_stats.set_index(['warehouse','date'])['ewmean_orders_56'])\n",
    "    #每个商店在14天的窗口的med_total_orders的普通平均.\n",
    "    df['mean_orders_14d'] = pd.MultiIndex.from_frame(df[['warehouse','date']]).map(\n",
    "        warehouse_stats.groupby('warehouse').rolling(on='date',window='14D')['med_total_orders'].mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b8222",
   "metadata": {
    "papermill": {
     "duration": 0.004701,
     "end_time": "2025-03-09T13:35:40.017309",
     "exception": false,
     "start_time": "2025-03-09T13:35:40.012608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "这里主要就是读取训练数据和测试数据,然后把fe_date,fe_other和fe_combined过一遍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf6f4dc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T13:35:40.028163Z",
     "iopub.status.busy": "2025-03-09T13:35:40.027776Z",
     "iopub.status.idle": "2025-03-09T13:37:01.135246Z",
     "shell.execute_reply": "2025-03-09T13:37:01.134228Z"
    },
    "papermill": {
     "duration": 81.115204,
     "end_time": "2025-03-09T13:37:01.137308",
     "exception": false,
     "start_time": "2025-03-09T13:35:40.022104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< sell_price_main features >\n",
      "< total orders features >\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_train.csv', parse_dates=['date'])\n",
    "train['id'] = train['unique_id'].astype('str') + '_' + train['date'].astype('str')\n",
    "train.set_index('id',inplace=True)\n",
    "train = train[~train['sales'].isna()]\n",
    "train = train.reset_index().merge(inventory, on='unique_id').set_index('id').loc[train.index]\n",
    "train = train.reset_index().merge(calendar, on=['date','warehouse']).set_index('id').loc[train.index]\n",
    "fe_date(train)\n",
    "fe_other(train)\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_test.csv', parse_dates=['date'])\n",
    "test['id'] = test['unique_id'].astype('str') + '_' + test['date'].astype('str')\n",
    "test.set_index('id',inplace=True)\n",
    "test = test.reset_index().merge(inventory, on='unique_id').set_index('id').loc[test.index]\n",
    "test = test.reset_index().merge(calendar, on=['date','warehouse']).set_index('id')\n",
    "fe_date(test)\n",
    "fe_other(test)\n",
    "\n",
    "all_data = pd.concat([train,test])\n",
    "all_data = fe_combined(all_data)\n",
    "train = all_data.loc[train.index]\n",
    "test = all_data.loc[test.index].drop(['sales','availability'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95974965",
   "metadata": {
    "papermill": {
     "duration": 0.00476,
     "end_time": "2025-03-09T13:37:01.147333",
     "exception": false,
     "start_time": "2025-03-09T13:37:01.142573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "去除训练数据:X_train,y_train,X_train_weights. sales是需要预测的变量,availability是测试数据没有,所以删除掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcea9c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T13:37:01.158649Z",
     "iopub.status.busy": "2025-03-09T13:37:01.158301Z",
     "iopub.status.idle": "2025-03-09T13:37:01.831944Z",
     "shell.execute_reply": "2025-03-09T13:37:01.830906Z"
    },
    "papermill": {
     "duration": 0.681624,
     "end_time": "2025-03-09T13:37:01.833931",
     "exception": false,
     "start_time": "2025-03-09T13:37:01.152307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['sales','availability'],axis=1)\n",
    "y_train = train['sales']\n",
    "weights = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/test_weights.csv').set_index('unique_id')\n",
    "X_train_weights = X_train['unique_id'].map(weights['weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c079a36c",
   "metadata": {
    "papermill": {
     "duration": 0.00498,
     "end_time": "2025-03-09T13:37:01.844235",
     "exception": false,
     "start_time": "2025-03-09T13:37:01.839255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "这里其实增加的就是add_cols这3个特征.\n",
    "\n",
    "last_sales_ema005:每个仓库每种细分的商品的sales的指数加权移动平均。\n",
    "\n",
    "CN_sales_sum:每个仓库每天对每个粗略的商品的last_sales_ema005求和.\n",
    "\n",
    "last_sales_zs:对last_sales_ema005进行了z-score处理.\n",
    "\n",
    "这里选择了2022年1月1日以后的数据进行了训练."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41dfeebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T13:37:01.855873Z",
     "iopub.status.busy": "2025-03-09T13:37:01.855495Z",
     "iopub.status.idle": "2025-03-09T13:38:15.566303Z",
     "shell.execute_reply": "2025-03-09T13:38:15.565252Z"
    },
    "papermill": {
     "duration": 73.718808,
     "end_time": "2025-03-09T13:38:15.568197",
     "exception": false,
     "start_time": "2025-03-09T13:37:01.849389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_cols = ['unique_id'] + list(X_train.columns[X_train.dtypes == 'object'])\n",
    "all_data = pd.concat([X_train, test])\n",
    "add_cols = ['last_sales_ema005','CN_sales_sum','last_sales_zs']\n",
    "\n",
    "train_cp = train.groupby('unique_id')['date'].apply(lambda s: pd.date_range(s.min(), test.date.max())).explode().reset_index()\n",
    "train_cp = train_cp.merge(\n",
    "    pd.concat([train[['unique_id','date','sales','warehouse']], \n",
    "               test[['unique_id','date','warehouse']]]),\n",
    "    on=['unique_id','date'],how='left')\n",
    "train_cp = train_cp.merge(inventory, left_on='unique_id', right_index=True)\n",
    "train_cp['common_name'] = train_cp['name'].apply(lambda x: x[:x.find('_')])\n",
    "train_cp.sort_values('date',inplace=True)\n",
    "train_cp['last_sales_ema005'] = train_cp.groupby(['unique_id'])['sales'].transform(lambda x: x.shift(1).ewm(alpha=.005).mean()).fillna(0)\n",
    "train_cp['CN_sales_sum'] = train_cp.groupby(['common_name','warehouse','date'])['last_sales_ema005'].transform('sum')\n",
    "all_data = all_data.merge(train_cp.set_index(['unique_id','date'])[[\n",
    "    'last_sales_ema005','CN_sales_sum'\n",
    "]], left_on=['unique_id','date'],right_index=True,how='left')\n",
    "sales_stats = train_cp.groupby(['common_name','warehouse'])['sales'].agg(['mean','std'])\n",
    "all_data['last_sales_zs'] = (all_data['last_sales_ema005'] - pd.MultiIndex.from_frame(all_data[['common_name','warehouse']]).map(\n",
    "    sales_stats['mean']))/ pd.MultiIndex.from_frame(all_data[['common_name','warehouse']]).map(sales_stats['std'])\n",
    "\n",
    "X_train = X_train[X_train['date'] >= '2022-01-01']\n",
    "y_train = y_train.loc[X_train.index]\n",
    "X_train_weights = X_train_weights.loc[X_train.index]\n",
    "\n",
    "X_train[add_cols] = all_data[add_cols]\n",
    "test[add_cols] = all_data[add_cols]\n",
    "all_data[cat_cols] = all_data[cat_cols].astype('str').astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6fb1eb",
   "metadata": {
    "papermill": {
     "duration": 0.004985,
     "end_time": "2025-03-09T13:38:15.578902",
     "exception": false,
     "start_time": "2025-03-09T13:38:15.573917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "这里就是普通的k折交叉验证,唯一的亮点就是在模型训练之前开平方,预测之后再把平方复原回去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b34c2db7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T13:38:15.590901Z",
     "iopub.status.busy": "2025-03-09T13:38:15.590531Z",
     "iopub.status.idle": "2025-03-09T15:22:10.264959Z",
     "shell.execute_reply": "2025-03-09T15:22:10.262415Z"
    },
    "papermill": {
     "duration": 6234.683112,
     "end_time": "2025-03-09T15:22:10.267324",
     "exception": false,
     "start_time": "2025-03-09T13:38:15.584212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:5.86580\n",
      "[1000]\tvalidation_0-rmse:1.26942\n",
      "[2000]\tvalidation_0-rmse:1.23773\n",
      "[2292]\tvalidation_0-rmse:1.23398\n",
      "[0]\tvalidation_0-rmse:5.91743\n",
      "[1000]\tvalidation_0-rmse:1.26903\n",
      "[2000]\tvalidation_0-rmse:1.23575\n",
      "[2377]\tvalidation_0-rmse:1.23093\n",
      "[0]\tvalidation_0-rmse:5.88980\n",
      "[1000]\tvalidation_0-rmse:1.26632\n",
      "[1645]\tvalidation_0-rmse:1.24039\n",
      "[0]\tvalidation_0-rmse:5.85311\n",
      "[1000]\tvalidation_0-rmse:1.26425\n",
      "[2000]\tvalidation_0-rmse:1.23110\n",
      "[2106]\tvalidation_0-rmse:1.22932\n",
      "[0]\tvalidation_0-rmse:5.90635\n",
      "[1000]\tvalidation_0-rmse:1.27021\n",
      "[2000]\tvalidation_0-rmse:1.23754\n",
      "[2119]\tvalidation_0-rmse:1.23524\n"
     ]
    }
   ],
   "source": [
    "#xgb模型的参数.\n",
    "xgb_params = {\n",
    "    'n_estimators':50000\n",
    "    ,'learning_rate':0.1\n",
    "    ,'verbosity':0\n",
    "    ,'enable_categorical':True\n",
    "    ,'early_stopping_rounds':10\n",
    "    ,'random_state':2025\n",
    "    ,'objective':'reg:squarederror'\n",
    "    ,'eval_metric':'rmse'\n",
    "    ,'device':'cuda'\n",
    "    ,'reg_lambda':0\n",
    "    ,'min_child_weight':1\n",
    "}\n",
    "\n",
    "drop_cols = ['date','name','L1_category_name_en']#一些字符串,去掉\n",
    "oof_preds = []\n",
    "test_preds = []\n",
    "n_splits=5\n",
    "kf = KFold(n_splits=n_splits,shuffle=True,random_state=2025)\n",
    "X,y = deepcopy(X_train),deepcopy(y_train)\n",
    "X[cat_cols] = all_data[cat_cols]\n",
    "X.drop(drop_cols,axis=1,inplace=True)\n",
    "test_copy = deepcopy(test)\n",
    "test_copy[cat_cols] = all_data[cat_cols]\n",
    "test_copy.drop(drop_cols,axis=1,inplace=True)\n",
    "oof_pred_df = pd.DataFrame(index=X.index, columns=['Pred_0'])\n",
    "for i, (idx_t, idx_v) in enumerate(kf.split(X)):\n",
    "    X_t, X_v = X.iloc[idx_t], X.iloc[idx_v]        \n",
    "    y_t, y_v = y.loc[X_t.index], y.loc[X_v.index]\n",
    " \n",
    "    y_t, y_v = np.power(y_t,0.5), np.power(y_v,0.5)\n",
    "    xgb = XGBRegressor(**xgb_params)\n",
    "    xgb.fit(X_t, y_t, eval_set=[(X_v, y_v)], verbose=1000)\n",
    "    model_test_preds = np.power(xgb.predict(test_copy).clip(0), 2) \n",
    "    test_preds.append(model_test_preds)\n",
    "    model_oof_preds = np.power(xgb.predict(X_v).clip(0), 2)\n",
    "    oof_pred_df.iloc[idx_v,int(i/n_splits)] = model_oof_preds\n",
    "oof_preds.append(oof_pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536e203",
   "metadata": {
    "papermill": {
     "duration": 0.006286,
     "end_time": "2025-03-09T15:22:10.280570",
     "exception": false,
     "start_time": "2025-03-09T15:22:10.274284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "计算线下的WMAE评估指标,不过由于使用的是普通的kfold,所以线下CV肯定是偏低的."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38dcba39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T15:22:10.296201Z",
     "iopub.status.busy": "2025-03-09T15:22:10.295721Z",
     "iopub.status.idle": "2025-03-09T15:22:13.442905Z",
     "shell.execute_reply": "2025-03-09T15:22:13.441645Z"
    },
    "papermill": {
     "duration": 3.15736,
     "end_time": "2025-03-09T15:22:13.444655",
     "exception": false,
     "start_time": "2025-03-09T15:22:10.287295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMAE:13.327\n"
     ]
    }
   ],
   "source": [
    "#评估指标mae\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "oof_pred_df = pd.concat(oof_preds,axis=1)\n",
    "oof_pred_vals = oof_pred_df.mean(axis=1)\n",
    "print(f'WMAE:{np.round(mean_absolute_error(y_train, oof_pred_vals, sample_weight=X_train_weights), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd224768",
   "metadata": {
    "papermill": {
     "duration": 0.006506,
     "end_time": "2025-03-09T15:22:13.458567",
     "exception": false,
     "start_time": "2025-03-09T15:22:13.452061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "将测试数据的预测结果保存到submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8837ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T15:22:13.476774Z",
     "iopub.status.busy": "2025-03-09T15:22:13.476359Z",
     "iopub.status.idle": "2025-03-09T15:22:13.593399Z",
     "shell.execute_reply": "2025-03-09T15:22:13.592194Z"
    },
    "papermill": {
     "duration": 0.12855,
     "end_time": "2025-03-09T15:22:13.595551",
     "exception": false,
     "start_time": "2025-03-09T15:22:13.467001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_pred_df = pd.DataFrame(np.transpose(test_preds), index=test.index)\n",
    "test_sub = test_pred_df.mean(axis=1)\n",
    "test_sub.name = 'sales_hat'\n",
    "test_sub.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10173359,
     "sourceId": 88742,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6403.014091,
   "end_time": "2025-03-09T15:22:16.632961",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-09T13:35:33.618870",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
